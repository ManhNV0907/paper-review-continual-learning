# Learning from a Teacher using Unlabeled Data
This paper introduces a new option of knowledge distillation called blind distillation.

The experiments show that blind distillation + fine tuning (read 3.2 for more details of this type of fine tuning) helps student outperform teacher in few cases.
Its a new kind of distillation. I like it !
